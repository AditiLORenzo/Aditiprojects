{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdrqgCrbIYPL3Hh5yrGo/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AditiLORenzo/Aditiprojects/blob/main/EDA_on_Text_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70TawQtfiC5D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u04bYVjG51n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Data"
      ],
      "metadata": {
        "id": "YloVK8xBk4MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/news_syn (3).csv')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "CiVvVjmwk3Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1vkwSGuFnQZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "CVvCI7AdrjjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check wheather there is any null values"
      ],
      "metadata": {
        "id": "igXkx-Qklgga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "eZ9e3XP_lj_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "r3lcZi8Jlq3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "om3JFOKjlyI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "CNpW4TiImGFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Article category'].shape[0]"
      ],
      "metadata": {
        "id": "0ouZE5synoti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df=df.groupby('Article category ').filter(lambda x:len(x)>500).reset_index(drop=True)\n",
        "#print(\"number of article>=\",len(df['Article category'].unique()))\n",
        "df=df.groupby('Article category').filter(lambda x:len(x)<500).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wbCBkkuYnBZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of article>=\",len(df['Article category'].unique()))"
      ],
      "metadata": {
        "id": "EaO8S5qxptUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Article category'].unique()"
      ],
      "metadata": {
        "id": "eeg8XJO9qgAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting categorical data to integers\n",
        "#df['short_description']=df['short_description'].astype(int)"
      ],
      "metadata": {
        "id": "90ZFsWTQqu8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['News Headline'].unique())"
      ],
      "metadata": {
        "id": "PvwnDvnotHT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "mAjDggar-upa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Text data"
      ],
      "metadata": {
        "id": "k36SPnEK-jwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['News Headline']=df['News Headline'].apply(lambda x:x.split(',,,')[0])"
      ],
      "metadata": {
        "id": "Oi4Dnm58-olq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['News Headline']"
      ],
      "metadata": {
        "id": "rSMZUFn1_mqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['short_description'].unique())"
      ],
      "metadata": {
        "id": "jTo14elFC1Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,text in enumerate(df['News Headline'][18:23]):\n",
        "    print('News headlines%d:\\n'%(index+1),text)"
      ],
      "metadata": {
        "id": "3OOmwNJl_ZWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,text in enumerate(df['short_description'][35:40]):\n",
        "    print('Short description%d:\\n'%(index+1),text)"
      ],
      "metadata": {
        "id": "Ccf498jVDHfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                     \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "pnblrB_lAjJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regular expression for finding the contraction\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, text)\n",
        "\n",
        "df['News Headline']=df['News Headline'].apply(lambda x:expand_contractions(x))  \n",
        "df['short_description']=df['short_description'].apply(lambda x:expand_contractions(x))"
      ],
      "metadata": {
        "id": "pkYDdXCgBQtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower case "
      ],
      "metadata": {
        "id": "Zkurw-07Eatc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['News Headline']=df['News Headline'].apply(lambda x: x.lower())\n",
        "df['short_description']=df['short_description'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "b6ePlExMCifv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing digits"
      ],
      "metadata": {
        "id": "GQmT-6Pil4Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['News Headline']=df['News Headline'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
        "df['short_description']=df['short_description'].apply(lambda x: re.sub('\\w*\\d\\w*','',x))"
      ],
      "metadata": {
        "id": "Nkm6DkLQl6en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove puntuation"
      ],
      "metadata": {
        "id": "nUopUgfrmWtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['News Headline']=df['News Headline'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
        "df['short_description']=df['short_description'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
      ],
      "metadata": {
        "id": "ceKhZeaKmZYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing EDA"
      ],
      "metadata": {
        "id": "4X6TGNrfnS2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Loading model\n",
        "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
        "\n",
        "# Lemmatization with stopwords removal\n",
        "df['lemmatized1']=df['News Headline'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))\n",
        "df['lemmatized2']=df['short_description'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
      ],
      "metadata": {
        "id": "b05iodKTnUhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped=df[['News Headline','short_description','lemmatized1','lemmatized2']].groupby(by='News Headline').agg(lambda x:' '.join(x))\n",
        "df_grouped.head()"
      ],
      "metadata": {
        "id": "Fx0rEvUroj-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating document term matrix"
      ],
      "metadata": {
        "id": "1THH73FlpUqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(analyzer='word')\n",
        "data=cv.fit_transform(df_grouped['lemmatized1'])\n",
        "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
        "df_dtm.index=df_grouped.index\n",
        "df_dtm.head(3)"
      ],
      "metadata": {
        "id": "sYlXu38BpM9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer(analyzer='word')\n",
        "data=cv.fit_transform(df_grouped['lemmatized2'])\n",
        "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
        "df_dtm.index=df_grouped.index\n",
        "df_dtm.head(3)"
      ],
      "metadata": {
        "id": "QPZWzXoLqH6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import wrap\n",
        "\n"
      ],
      "metadata": {
        "id": "vjYU7io_qNJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for generating word cloud\n",
        "from wordcloud import WordCloud \n",
        "def generate_wordcloud(data,title):\n",
        "    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OR0UTUpXqo6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm=df_dtm.transpose()"
      ],
      "metadata": {
        "id": "e2LdUCMDrE-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,product in enumerate(df_dtm.columns):\n",
        "    generate_wordcloud(df_dtm[product].sort_values(ascending=False),product)"
      ],
      "metadata": {
        "id": "Gy_MJ7xErvDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "df['polarity1']=df['lemmatized1'].apply(lambda x:TextBlob(x).sentiment.polarity)\n",
        "df['polarity2']=df['lemmatized2'].apply(lambda x:TextBlob(x).sentiment.polarity)"
      ],
      "metadata": {
        "id": "GydRknKosdAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"10 Random News headline with Highest Polarity:\")\n",
        "for index,review in enumerate(df.iloc[df['polarity1'].sort_values(ascending=False)[:10].index]['News Headline']):\n",
        "    print('News Headline {}:\\n'.format(index+1),review)"
      ],
      "metadata": {
        "id": "YqW9w556tU-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"5 Random short_description with Highest Polarity:\")\n",
        "for index,review in enumerate(df.iloc[df['polarity2'].sort_values(ascending=False)[:5].index]['short_description']):\n",
        "  print('short description {}:\\n'.format(index+1),review)"
      ],
      "metadata": {
        "id": "ojAOLX2utm5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"5 Random short description with Lowest Polarity:\")\n",
        "for index,review in enumerate(df.iloc[df['polarity1'].sort_values(ascending=True)[:5].index]['short_description']):\n",
        "  print('Review {}:\\n'.format(index+1),review)"
      ],
      "metadata": {
        "id": "mScul7t5vYWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"5 Random news headline with Lowest Polarity:\")\n",
        "for index,review in enumerate(df.iloc[df['polarity2'].sort_values(ascending=True)[:5].index]['News Headline']):\n",
        "  print('Review {}:\\n'.format(index+1),review)"
      ],
      "metadata": {
        "id": "S1CPxMymvqaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets plot polarity result"
      ],
      "metadata": {
        "id": "hLZZ2CIOwgma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_polarity_sorted=pd.DataFrame(df.groupby('short_description')['polarity2'].mean().sort_values(ascending=True))\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('description')\n",
        "plt.title('Polarity of News short description')\n",
        "polarity_graph=plt.barh(np.arange(len(product_polarity_sorted.index)),product_polarity_sorted['polarity2'],color='purple',)\n",
        "\n",
        "# Writing product names on bar\n",
        "for bar,product in zip(polarity_graph,product_polarity_sorted.index):\n",
        "  plt.text(0.005,bar.get_y()+bar.get_width(),'{}'.format(product),va='center',fontsize=11,color='white')\n",
        "\n",
        "# Writing polarity values on graph\n",
        "for bar,polarity in zip(polarity_graph,product_polarity_sorted['polarity2']):\n",
        "  plt.text(bar.get_width()+0.001,bar.get_y()+bar.get_width(),'%.3f'%polarity,va='center',fontsize=11,color='black')\n",
        "  \n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zpFWEVhXwKGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_polarity_sorted=pd.DataFrame(df.groupby('News Headline')['polarity1'].mean().sort_values(ascending=True))\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('description')\n",
        "plt.title('Polarity of News short description')\n",
        "polarity_graph=plt.barh(np.arange(len(product_polarity_sorted.index)),product_polarity_sorted['polarity1'],color='purple',)\n",
        "\n",
        "# Writing product names on bar\n",
        "for bar,product in zip(polarity_graph,product_polarity_sorted.index):\n",
        "  plt.text(0.005,bar.get_y()+bar.get_width(),'{}'.format(product),va='center',fontsize=11,color='white')\n",
        "\n",
        "# Writing polarity values on graph\n",
        "for bar,polarity in zip(polarity_graph,product_polarity_sorted['polarity1']):\n",
        "  plt.text(bar.get_width()+0.001,bar.get_y()+bar.get_width(),'%.3f'%polarity,va='center',fontsize=11,color='black')\n",
        "  \n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T69Ts2YCyFI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}